# Karpathy Deep Learning Series ‚Äì Colab Notebooks

This repository contains my personal implementations and explorations of Andrej Karpathy's [Neural Networks: Zero to Hero](https://www.youtube.com/playlist?list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ) YouTube series. All code is written and run in Google Colab, with a focus on understanding the core building blocks of deep learning from scratch.

## üìò Notebooks Overview

| Notebook | Description |
|---------|-------------|
| **1 - Introduction to Bigram & Pytorch** | Implements a character-level name generator using a simple bigram model. Introduces basic data processing and modeling. |
| **2 - Introduction to MLP & Embeddings** | Builds a neural network (MLP) from scratch in pure Python, exploring gradients and training mechanics. |
| **3 - Deep-dive into Activations and Batch Normalization** | Explores training improvements using techniques like Batch Normalization and tanh non-linearity. |
| **4 - Backprop Ninja** | Doing backpropagation by hand ;) |
| **5 - Implementing Wavenet** | Constructs a WaveNet-inspired model for character-level generation using causal convolutions. |


## üìö Learning Goals

- Understand the internals of neural networks, backpropagation, and training
- Build deep learning models from scratch without frameworks
- Get comfortable with PyTorch and deep learning patterns
- Apply modern techniques like normalization

## üôè Credits

All credit for the teaching and original ideas goes to [Andrej Karpathy](https://github.com/karpathy). This is purely for educational and learning purposes.

---

Feel free to fork, star, or reach out if you're on the same learning path!
